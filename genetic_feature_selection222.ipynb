{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Genetic Algorithm Feature Selection for Football Match Prediction\n",
    "This notebook implements a genetic algorithm to select the best features for predicting football match outcomes using a neural network model. The model is trained and evaluated on the selected features."
   ],
   "id": "9a5b3815ba6056d2"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch import nn\n",
    "import pygad\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from codecarbon import EmissionsTracker\n",
    "import logging"
   ],
   "id": "5283e76a8e5add09",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "The architecture of the neural network is the same as the one used in the prediction_model.ipynb notebook",
   "id": "b142f15ae875d920"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "class RegularizedFootballModel(nn.Module):\n",
    "    def __init__(self, input_features):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.network = nn.Sequential(\n",
    "            # First block\n",
    "            nn.Linear(input_features, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            \n",
    "            # Second block\n",
    "            nn.Linear(128, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.2),\n",
    "            \n",
    "            # Third block\n",
    "            nn.Linear(64, 32),\n",
    "            nn.ReLU(),\n",
    "            \n",
    "            # Output layer\n",
    "            nn.Linear(32, 1)\n",
    "        )\n",
    "        \n",
    "        for layer in self.network:\n",
    "            if isinstance(layer, nn.Linear):\n",
    "                nn.init.xavier_uniform_(layer.weight)\n",
    "                nn.init.zeros_(layer.bias)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.network(x)"
   ],
   "id": "705de69a919eb6e7",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "```load_data``` function loads the normalized football match dataset, fills missing values, selects predictive features, and splits the data into training, validation and test sets",
   "id": "2f141b6b1f0547ec"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def load_data():\n",
    "    df = pd.read_csv('data/normalized/normalized_matches_df.csv')\n",
    "    df.fillna(df.mean(), inplace=True)\n",
    "    \n",
    "    # Feature selection\n",
    "    predictive_features = [\n",
    "        'HT_Form', 'AT_Form',\n",
    "        'HT_W_Odds', 'Draw_Odds', 'AT_W_Odds',\n",
    "        '5GAV_FT_HT_Goals', '5GAV_FT_AT_Goals',\n",
    "        '5GAV_HT_Shots', '5GAV_AT_Shots',\n",
    "        '5GAV_HT_Shots_target', '5GAV_AT_Shots_target',\n",
    "        '5GAV_HT_Corners', '5GAV_AT_Corners',\n",
    "        'AVG_Influence_HT', 'AVG_ICT_Index_HT',\n",
    "        'AVG_Influence_AT', 'AVG_ICT_Index_AT',\n",
    "        'Injured_Players_HT', 'Injured_Players_AT',\n",
    "        'HT_Players_Performances', 'AT_Players_Performances'\n",
    "    ]\n",
    "    \n",
    "    X = df[predictive_features]\n",
    "    y = df[\"FT_Result_code\"]  # Target variable: 1 if home team wins, 0 otherwise\n",
    "    \n",
    "    # Convert to PyTorch tensors\n",
    "    X_tensor = torch.tensor(X.values, dtype=torch.float32)\n",
    "    y_tensor = torch.tensor(y.values, dtype=torch.float32)\n",
    "\n",
    "\n",
    "    # First split: 10% test, 90% temp\n",
    "    X_temp, X_test, y_temp, y_test = train_test_split(X_tensor, y_tensor, test_size=0.1, random_state=42)\n",
    "\n",
    "    # Second split: From the 90% temp, split 8/9 for training and 1/9 for validation\n",
    "    X_train, X_val, y_train, y_val = train_test_split(\n",
    "        X_temp, y_temp, test_size=1/9, random_state=42\n",
    "    )\n",
    "\n",
    "\n",
    "    print(f\"Train: {len(X_train)}, Val: {len(X_val)}, Test: {len(X_test)}\")\n",
    "\n",
    "    print(f\"Feature dimensions: {X_train.shape[1]}\")\n",
    "    return X_train, X_val, X_test, y_train, y_val, y_test, predictive_features\n"
   ],
   "id": "13da28995450940d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "\n",
    "Helper functions to create models with selected features and to train and evaluate models"
   ],
   "id": "d2437386e66e3ba8"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def create_model_with_selected_features(selected_features_mask, device):\n",
    "    num_selected_features = np.sum(selected_features_mask)\n",
    "    model = RegularizedFootballModel(num_selected_features).to(device)\n",
    "    return model\n",
    "\n",
    "def train_model(model, X_train, y_train, X_test, y_test, device, epochs=100):\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "    loss_fn = nn.BCEWithLogitsLoss()\n",
    "\n",
    "    X_train = X_train.to(device)\n",
    "    y_train = y_train.to(device)\n",
    "    X_test = X_test.to(device)\n",
    "    y_test = y_test.to(device)\n",
    "    \n",
    "    # Training loop\n",
    "    model.train()\n",
    "    for epoch in range(epochs):\n",
    "        optimizer.zero_grad()\n",
    "        y_pred = model(X_train)\n",
    "        loss = loss_fn(y_pred.squeeze(), y_train)\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "        optimizer.step()\n",
    "    \n",
    "    # Evaluate on test set\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        y_pred = model(X_test)\n",
    "        y_pred_binary = (torch.sigmoid(y_pred.squeeze()) > 0.5).float()\n",
    "        accuracy = (y_pred_binary == y_test).float().mean().item()\n",
    "    \n",
    "    return accuracy"
   ],
   "id": "c06c03d8bdad018a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Defines the fitness function for the genetic algorithm. Each individual represents a subset of features, and the fitness is the model's accuracy using those features.",
   "id": "954ea86444c49c78"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def fitness_function(ga_instance, solution, solution_idx):\n",
    "    feature_mask = solution.astype(bool)\n",
    "\n",
    "    if not np.any(feature_mask):\n",
    "        return 0\n",
    "\n",
    "    # Use validation data for evaluation\n",
    "    X_train_selected = X_train[:, feature_mask]\n",
    "    X_val_selected = X_val[:, feature_mask]\n",
    "\n",
    "    model = create_model_with_selected_features(feature_mask, device)\n",
    "    accuracy = train_model(model, X_train_selected, y_train, X_val_selected, y_val, device)\n",
    "\n",
    "    return accuracy\n"
   ],
   "id": "30df1723d780f918",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "```run_genetic_algorithm``` function configures and runs the genetic algorithm to search for the optimal subset of features.",
   "id": "174ea2f07e445821"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def run_genetic_algorithm(X_train, X_val, X_test, y_train, y_val, y_test, predictive_features, device):\n",
    "    num_features = X_train.shape[1]\n",
    "\n",
    "    # GA parameters\n",
    "    num_generations = 30\n",
    "    num_parents_mating = 10\n",
    "    sol_per_pop = 20\n",
    "    num_genes = num_features\n",
    "    mutation_probability = 0.1\n",
    "\n",
    "    # Create the GA instance\n",
    "    ga_instance = pygad.GA(\n",
    "        num_generations=num_generations,\n",
    "        num_parents_mating=num_parents_mating,\n",
    "        sol_per_pop=sol_per_pop,\n",
    "        num_genes=num_genes,\n",
    "        fitness_func=fitness_function,\n",
    "        gene_type=int,\n",
    "        gene_space=[0, 1],  # Binary encoding for feature selection\n",
    "        mutation_probability=mutation_probability,\n",
    "        crossover_type=\"single_point\",\n",
    "        mutation_type=\"random\",\n",
    "        keep_parents=1\n",
    "    )\n",
    "\n",
    "    # Run the genetic algorithm\n",
    "    ga_instance.run()\n",
    "\n",
    "    # Get the best solution\n",
    "    solution, solution_fitness, solution_idx = ga_instance.best_solution()\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(ga_instance.best_solutions_fitness)\n",
    "    plt.title(\"Fitness Evolution\")\n",
    "    plt.xlabel(\"Generation\")\n",
    "    plt.ylabel(\"Fitness (Accuracy)\")\n",
    "    plt.grid(True)\n",
    "    plt.savefig(\"plots/genetic_algorithm_fitness_evolution.png\")\n",
    "    plt.close()\n",
    "\n",
    "    solution_mask = solution.astype(bool)\n",
    "    selected_feature_names = [feature for feature, mask in zip(predictive_features, solution_mask) if mask]\n",
    "    return solution_mask, selected_feature_names"
   ],
   "id": "1ecb7aeb5b21e650",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "After selecting the best features, we retrain the model and visualize its performance.",
   "id": "121304bbe0ce09db"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def train_final_model(selected_features_mask, X_train, y_train, X_val, y_val, X_test, y_test, device):\n",
    "    # Select features for all datasets\n",
    "    X_train_final = X_train[:, selected_features_mask]\n",
    "    X_val_final = X_val[:, selected_features_mask]\n",
    "    X_test_final = X_test[:, selected_features_mask]\n",
    "\n",
    "    # Create model and move to device\n",
    "    final_model = create_model_with_selected_features(selected_features_mask, device)\n",
    "    optimizer = torch.optim.Adam(final_model.parameters(), lr=0.001)\n",
    "    loss_fn = nn.BCEWithLogitsLoss()\n",
    "\n",
    "    # Move data to device\n",
    "    X_train_final = X_train_final.to(device)\n",
    "    y_train = y_train.to(device)\n",
    "    X_val_final = X_val_final.to(device)\n",
    "    y_val = y_val.to(device)\n",
    "    X_test_final = X_test_final.to(device)\n",
    "    y_test = y_test.to(device)\n",
    "\n",
    "    # Track validation metrics\n",
    "    train_losses = []\n",
    "    val_losses = []\n",
    "    train_accuracies = []\n",
    "    val_accuracies = []\n",
    "\n",
    "    epochs = 100\n",
    "    for epoch in range(epochs):\n",
    "        # Training phase\n",
    "        final_model.train()\n",
    "        y_logits = final_model(X_train_final)\n",
    "        y_pred = torch.round(torch.sigmoid(y_logits.squeeze()))\n",
    "        loss = loss_fn(y_logits.squeeze(), y_train)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(final_model.parameters(), max_norm=1.0)\n",
    "        optimizer.step()\n",
    "\n",
    "        # Calculate training accuracy\n",
    "        acc = (y_pred == y_train).float().mean().item() * 100\n",
    "\n",
    "        # Validation phase\n",
    "        final_model.eval()\n",
    "        with torch.no_grad():\n",
    "            val_logits = final_model(X_val_final)\n",
    "            val_pred = torch.round(torch.sigmoid(val_logits.squeeze()))\n",
    "            val_loss = loss_fn(val_logits.squeeze(), y_val)\n",
    "            val_acc = (val_pred == y_val).float().mean().item() * 100\n",
    "\n",
    "        # Update metrics\n",
    "        train_losses.append(loss.item())\n",
    "        val_losses.append(val_loss.item())\n",
    "        train_accuracies.append(acc)\n",
    "        val_accuracies.append(val_acc)\n",
    "\n",
    "        if epoch % 10 == 0 or epoch == epochs - 1:\n",
    "            print(f\"Epoch: {epoch} | Loss: {loss:.5f}, Train acc: {acc:.2f}% | \"\n",
    "                  f\"Val loss: {val_loss:.5f}, Val acc: {val_acc:.2f}%\")\n",
    "\n",
    "    # Final test evaluation\n",
    "    final_model.eval()\n",
    "    with torch.no_grad():\n",
    "        test_logits = final_model(X_test_final)\n",
    "        test_pred = torch.round(torch.sigmoid(test_logits.squeeze()))\n",
    "        test_loss = loss_fn(test_logits.squeeze(), y_test)\n",
    "        test_acc = (test_pred == y_test).float().mean().item() * 100\n",
    "\n",
    "\n",
    "    # Plotting\n",
    "    plt.figure(figsize=(12, 5))\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(train_accuracies, label=\"Train accuracy\", color=\"#6E0096\")\n",
    "    plt.plot(val_accuracies, label=\"Validation accuracy\", color=\"#FFA600\")\n",
    "    plt.title(\"Accuracy Curves\")\n",
    "    plt.xlabel(\"Epochs\")\n",
    "    plt.ylabel(\"Accuracy (%)\")\n",
    "    plt.legend()\n",
    "\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(train_losses, label=\"Train loss\", color=\"#6E0096\")\n",
    "    plt.plot(val_losses, label=\"Validation loss\", color=\"#FFA600\")\n",
    "    plt.title(\"Loss Curves\")\n",
    "    plt.xlabel(\"Epochs\")\n",
    "    plt.ylabel(\"Loss\")\n",
    "    plt.legend()\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    torch.save(final_model.state_dict(), \"models/genetic_optimized_model.pth\")\n",
    "\n",
    "\n",
    "    return {\n",
    "        'model': final_model,\n",
    "        'train_losses': train_losses,\n",
    "        'val_losses': val_losses,\n",
    "        'train_accuracies': train_accuracies,\n",
    "        'val_accuracies': val_accuracies,\n",
    "        'test_accuracy': test_acc\n",
    "    }\n"
   ],
   "id": "40f7f144ab32590f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Now execute the entire pipeline: load data, run genetic algorithm for feature selection, retrain with selected features, and compare results.",
   "id": "41572f1b124a160"
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Suppress CodeCarbon's INFO logs\n",
    "logging.getLogger(\"codecarbon\").setLevel(logging.WARNING)\n",
    "\n",
    "# Updated main execution flow\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "X_train, X_val, X_test, y_train, y_val, y_test, predictive_features = load_data()\n",
    "\n",
    "final_test_accuracy = 0\n",
    "attempt = 1\n",
    "\n",
    "# Start CO2 emissions tracking\n",
    "tracker = EmissionsTracker(output_dir=\"codecarbon_logs\", measure_power_secs=1,log_level=\"error\")\n",
    "tracker.start()\n",
    "\n",
    "\n",
    "selected_features_mask, selected_feature_names = run_genetic_algorithm(\n",
    "    X_train, X_val, X_test, y_train, y_val, y_test, predictive_features, device\n",
    ")\n",
    "\n",
    "final_results = train_final_model(\n",
    "    selected_features_mask,\n",
    "    X_train, y_train,\n",
    "    X_val, y_val,\n",
    "    X_test, y_test,\n",
    "    device\n",
    ")\n",
    "\n",
    "final_test_accuracy = final_results['test_accuracy']\n",
    "final_model = final_results['model']\n",
    "final_val_accuracy = final_results['val_accuracies'][-1]\n",
    "\n",
    "\n",
    "# Stop CO2 emissions tracking\n",
    "emissions: float = tracker.stop()\n",
    "\n",
    "print(f\"Final test accuracy: {final_test_accuracy:.2f}%\")\n",
    "print(f\"CO₂ emissions (kg): {emissions:.6f}\")\n",
    "print(f\"Number of original features: {len(predictive_features)}\")\n",
    "print(f\"Number of selected features: {np.sum(selected_features_mask)}\")\n",
    "print(\"Selected features:\")\n",
    "for feature in selected_feature_names:\n",
    "    print(f\"- {feature}\")\n",
    "\n",
    "torch.save(final_model.state_dict(), \"models/genetic_optimized_model.pth\")\n"
   ],
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
